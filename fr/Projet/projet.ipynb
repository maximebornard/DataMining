{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72c8370",
   "metadata": {},
   "source": [
    "TÂCHE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48862361",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install sparqlwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ff23eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                label        pays  \\\n",
       " 0           Antofalla   Argentine   \n",
       " 1              Aracar   Argentine   \n",
       " 2       volcan Domuyo   Argentine   \n",
       " 3          Antillanca       Chili   \n",
       " 4          Acamarachi       Chili   \n",
       " 5         mont Mageik  États-Unis   \n",
       " 6                Solo       Chili   \n",
       " 7             Copahue       Chili   \n",
       " 8  volcan Antofagasta   Argentine   \n",
       " 9    Volcán Momotombo   Nicaragua   \n",
       " \n",
       "                                                image  \n",
       " 0  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 1  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 2  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 3  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 4  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 5  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 6  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 7  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 8  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 9  http://commons.wikimedia.org/wiki/Special:File...  ,\n",
       " 277)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Sujet: montagnes (Q8502)\n",
    "query = \"\"\"SELECT DISTINCT ?itemLabel ?paysLabel ?image WHERE {\n",
    "  ?item wdt:P31/wdt:P279* wd:Q8502 .\n",
    "  OPTIONAL { ?item wdt:P17 ?pays . }\n",
    "  ?item wdt:P18 ?image .\n",
    "  \n",
    "  FILTER(CONTAINS(STR(?image), \"commons.wikimedia.org\"))\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 300\n",
    "\"\"\"\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0], \n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append((\n",
    "        result[\"itemLabel\"][\"value\"],\n",
    "        result.get(\"paysLabel\", {}).get(\"value\"),\n",
    "        result[\"image\"][\"value\"]\n",
    "    ))\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"label\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.drop_duplicates(subset=[\"image\"]).reset_index(drop=True)\n",
    "\n",
    "dataframe.head(10), len(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1c65fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e3cf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    r = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        filename = os.path.basename(urlparse(url).path)\n",
    "        path = os.path.join(\"images\", filename)\n",
    "\n",
    "        with open(path, \"wb\") as img:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, img)\n",
    "    time.sleep(3)\n",
    "    return r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "daec8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement des 100 premières images\n",
    "#dataframe = dataframe.head(100)\n",
    "#dataframe[\"status\"] = dataframe[\"image\"].apply(download_image)\n",
    "\n",
    "#dataframe[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74e61315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "705dd938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrées JSON: 100\n",
      "Ignorées: 0\n"
     ]
    }
   ],
   "source": [
    "import os, json, time\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "IMG_DIR = \"images\"\n",
    "OUT_JSON = \"data/images_metadata.json\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# 1) Liste des fichiers\n",
    "files = sorted([\n",
    "    f for f in os.listdir(IMG_DIR)\n",
    "    if os.path.isfile(os.path.join(IMG_DIR, f))\n",
    "])\n",
    "\n",
    "# 2) Commons API pour la licence\n",
    "COMMONS_API = \"https://commons.wikimedia.org/w/api.php\"\n",
    "\n",
    "def get_license_info(file_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Récupère la licence via l'API Commons (extmetadata).\n",
    "    Retourne un dict simple.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": f\"File:{file_name}\",\n",
    "        \"prop\": \"imageinfo\",\n",
    "        \"iiprop\": \"extmetadata\",\n",
    "    }\n",
    "    headers = {\"User-Agent\": \"ImageRecoStudentProject/1.0\"}\n",
    "    r = requests.get(COMMONS_API, params=params, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "    page = next(iter(pages.values()), {})\n",
    "    infos = page.get(\"imageinfo\", [])\n",
    "    if not infos:\n",
    "        return {}\n",
    "\n",
    "    ext = infos[0].get(\"extmetadata\", {}) or {}\n",
    "    return {\n",
    "        \"license_short\": ext.get(\"LicenseShortName\", {}).get(\"value\"),\n",
    "        \"license_url\": ext.get(\"LicenseUrl\", {}).get(\"value\"),\n",
    "        \"usage_terms\": ext.get(\"UsageTerms\", {}).get(\"value\"),\n",
    "    }\n",
    "\n",
    "# 3) EXIF (si dispo)\n",
    "KEEP_EXIF = {\"Model\", \"Make\", \"DateTimeOriginal\", \"DateTime\", \"LensModel\"}\n",
    "\n",
    "def extract_exif_basic(img: Image.Image) -> dict:\n",
    "    try:\n",
    "        exif = img.getexif()\n",
    "        if not exif:\n",
    "            return {}\n",
    "        out = {}\n",
    "        for tag_id, value in exif.items():\n",
    "            tag = ExifTags.TAGS.get(tag_id, str(tag_id))\n",
    "            if tag in KEEP_EXIF and not isinstance(value, (bytes, bytearray)):\n",
    "                out[tag] = value\n",
    "        return out\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# 4) Construction du JSON\n",
    "metadata = []\n",
    "skipped = []\n",
    "\n",
    "for i, file_name in enumerate(files):\n",
    "    path = os.path.join(IMG_DIR, file_name)\n",
    "\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            width, height = img.size\n",
    "            fmt = img.format\n",
    "            exif = extract_exif_basic(img)\n",
    "\n",
    "        size_kb = os.path.getsize(path) / 1024\n",
    "\n",
    "        # URL source (reconstruite)\n",
    "        source_url = \"https://commons.wikimedia.org/wiki/Special:FilePath/\" + quote(file_name)\n",
    "\n",
    "        # licence (API)\n",
    "        license_info = get_license_info(file_name)\n",
    "\n",
    "        metadata.append({\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"format\": fmt,\n",
    "            \"file_size_kb\": round(size_kb, 2),\n",
    "\n",
    "            \"source_url\": source_url,\n",
    "            \"license\": license_info,\n",
    "            \"exif\": exif\n",
    "        })\n",
    "\n",
    "        time.sleep(0.1)  # politesse API (augmente si tu vois du 429)\n",
    "\n",
    "    except Exception as e:\n",
    "        skipped.append((file_name, str(e)))\n",
    "\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "print(\"Entrées JSON:\", len(metadata))\n",
    "print(\"Ignorées:\", len(skipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3cc63",
   "metadata": {},
   "source": [
    "TÂCHE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4949561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0321f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install scikit-learn pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8e0a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def dominant_colors_kmeans(image_path, k=4, sample_size=60000):\n",
    "    \"\"\"\n",
    "    Retourne une liste de k couleurs RGB dominantes (ints) triées par fréquence.\n",
    "    On échantillonne des pixels pour aller vite.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # option: réduire un peu si image énorme (accélère beaucoup)\n",
    "    max_side = 500\n",
    "    if max(img.size) > max_side:\n",
    "        ratio = max_side / max(img.size)\n",
    "        img = img.resize((int(img.size[0]*ratio), int(img.size[1]*ratio)))\n",
    "\n",
    "    pixels = np.array(img).reshape(-1, 3)\n",
    "\n",
    "    # échantillonnage pour accélérer\n",
    "    if len(pixels) > sample_size:\n",
    "        idx = np.random.choice(len(pixels), sample_size, replace=False)\n",
    "        pixels_sample = pixels[idx]\n",
    "    else:\n",
    "        pixels_sample = pixels\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, n_init=3, random_state=42)\n",
    "    labels = kmeans.fit_predict(pixels_sample)\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    # fréquence des clusters -> trier les couleurs par dominance\n",
    "    counts = np.bincount(labels)\n",
    "    order = np.argsort(counts)[::-1]\n",
    "\n",
    "    colors = []\n",
    "    for i in order:\n",
    "        r, g, b = centers[i]\n",
    "        colors.append([int(round(r)), int(round(g)), int(round(b))])\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4da5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_COLORS = {\n",
    "    \"noir\":   [0, 0, 0],\n",
    "    \"blanc\":  [255, 255, 255],\n",
    "    \"gris\":   [128, 128, 128],\n",
    "    \"rouge\":  [220, 20, 60],\n",
    "    \"orange\": [255, 140, 0],\n",
    "    \"jaune\":  [255, 215, 0],\n",
    "    \"vert\":   [34, 139, 34],\n",
    "    \"bleu\":   [30, 144, 255],\n",
    "    \"violet\": [138, 43, 226],\n",
    "    \"marron\": [139, 69, 19],\n",
    "}\n",
    "\n",
    "def rgb_to_color_name(rgb):\n",
    "    rgb = np.array(rgb)\n",
    "    best_name = None\n",
    "    best_dist = 1e18\n",
    "    for name, ref in BASIC_COLORS.items():\n",
    "        ref = np.array(ref)\n",
    "        dist = np.sum((rgb - ref) ** 2)\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_name = name\n",
    "    return best_name\n",
    "\n",
    "def color_names_from_rgbs(rgbs):\n",
    "    return [rgb_to_color_name(c) for c in rgbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a459f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientation_from_wh(width, height, tol=0.08):\n",
    "    r = width / height\n",
    "    if abs(r - 1.0) <= tol:\n",
    "        return \"carre\"\n",
    "    return \"paysage\" if width > height else \"portrait\"\n",
    "\n",
    "def size_category_from_wh(width, height):\n",
    "    m = max(width, height)\n",
    "    if m < 500:\n",
    "        return \"vignette\"\n",
    "    if m <= 1500:\n",
    "        return \"moyenne\"\n",
    "    return \"grande\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "983ada3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_tags(label=None, pays=None):\n",
    "    tags = [\"montagne\"]  # vu ton thème\n",
    "    if pays:\n",
    "        tags.append(pays.lower())\n",
    "    if label:\n",
    "        l = label.lower()\n",
    "        if \"volcan\" in l or \"volcano\" in l:\n",
    "            tags.append(\"volcan\")\n",
    "        if \"mont\" in l or \"mount\" in l:\n",
    "            tags.append(\"sommet\")\n",
    "    # enlever doublons en gardant l'ordre\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for t in tags:\n",
    "        if t and t not in seen:\n",
    "            seen.add(t)\n",
    "            out.append(t)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8d801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " [('%D0%92%D0%B5%D0%BB%D0%B8%D0%B2%D0%B0%D1%80%20%28%D0%94%D0%B5%D1%88%D0%B0%D1%82%29%2004.jpg',\n",
       "   {'predominant_colors': [[127, 141, 157],\n",
       "     [160, 174, 190],\n",
       "     [203, 207, 214],\n",
       "     [34, 33, 32]],\n",
       "    'color_names': ['gris', 'gris', 'blanc', 'noir'],\n",
       "    'orientation': 'paysage',\n",
       "    'size_category': 'moyenne',\n",
       "    'tags': ['montagne']})])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/images_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    meta_list = json.load(f)\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "for m in meta_list:\n",
    "    file_name = m[\"file_name\"]\n",
    "    image_path = os.path.join(\"images\", file_name)\n",
    "\n",
    "    # largeur/hauteur depuis metadata (plus rapide)\n",
    "    width = m.get(\"width\")\n",
    "    height = m.get(\"height\")\n",
    "\n",
    "    # couleurs dominantes\n",
    "    rgbs = dominant_colors_kmeans(image_path, k=4)  # mets 3,4,5 selon consigne\n",
    "    names = color_names_from_rgbs(rgbs)\n",
    "\n",
    "    labels_dict[file_name] = {\n",
    "        \"predominant_colors\": rgbs,\n",
    "        \"color_names\": names,\n",
    "        \"orientation\": orientation_from_wh(width, height),\n",
    "        \"size_category\": size_category_from_wh(width, height),\n",
    "        \"tags\": auto_tags(m.get(\"label\"), m.get(\"pays\")),\n",
    "    }\n",
    "\n",
    "with open(\"data/images_labels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(labels_dict, f, indent=2, ensure_ascii=False)\n",
    "print(dataframe[\"cityLabel\"])\n",
    "len(labels_dict), list(labels_dict.items())[:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
