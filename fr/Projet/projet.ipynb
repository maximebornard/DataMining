{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72c8370",
   "metadata": {},
   "source": [
    "TÂCHE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48862361",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install sparqlwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ff23eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                label        pays  \\\n",
       " 0           Antofalla   Argentine   \n",
       " 1              Aracar   Argentine   \n",
       " 2       volcan Domuyo   Argentine   \n",
       " 3          Antillanca       Chili   \n",
       " 4          Acamarachi       Chili   \n",
       " 5         mont Mageik  États-Unis   \n",
       " 6                Solo       Chili   \n",
       " 7             Copahue       Chili   \n",
       " 8  volcan Antofagasta   Argentine   \n",
       " 9    Volcán Momotombo   Nicaragua   \n",
       " \n",
       "                                                image  \n",
       " 0  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 1  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 2  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 3  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 4  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 5  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 6  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 7  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 8  http://commons.wikimedia.org/wiki/Special:File...  \n",
       " 9  http://commons.wikimedia.org/wiki/Special:File...  ,\n",
       " 277)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Sujet: montagnes (Q8502)\n",
    "query = \"\"\"SELECT DISTINCT ?itemLabel ?paysLabel ?image WHERE {\n",
    "  ?item wdt:P31/wdt:P279* wd:Q8502 .\n",
    "  OPTIONAL { ?item wdt:P17 ?pays . }\n",
    "  ?item wdt:P18 ?image .\n",
    "  \n",
    "  FILTER(CONTAINS(STR(?image), \"commons.wikimedia.org\"))\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 300\n",
    "\"\"\"\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0], \n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append((\n",
    "        result[\"itemLabel\"][\"value\"],\n",
    "        result.get(\"paysLabel\", {}).get(\"value\"),\n",
    "        result[\"image\"][\"value\"]\n",
    "    ))\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"label\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.drop_duplicates(subset=[\"image\"]).reset_index(drop=True)\n",
    "\n",
    "dataframe.head(10), len(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1c65fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e3cf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    r = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        filename = os.path.basename(urlparse(url).path)\n",
    "        path = os.path.join(\"images\", filename)\n",
    "\n",
    "        with open(path, \"wb\") as img:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, img)\n",
    "    time.sleep(3)\n",
    "    return r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "daec8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement des 100 premières images\n",
    "#dataframe = dataframe.head(100)\n",
    "#dataframe[\"status\"] = dataframe[\"image\"].apply(download_image)\n",
    "\n",
    "#dataframe[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74e61315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705dd938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrées JSON: 100\n",
      "Images ignorées: 0\n",
      "Exemple: {'file_name': '%D0%92%D0%B5%D0%BB%D0%B8%D0%B2%D0%B0%D1%80%20%28%D0%94%D0%B5%D1%88%D0%B0%D1%82%29%2004.jpg', 'width': 1280, 'height': 960, 'format': 'JPEG', 'file_size_kb': 592.88, 'source_url': None, 'label': None, 'pays': None, 'license': {}, 'exif': {'Make': 'SONY', 'Model': 'DSC-P120', 'DateTime': '2017:04:14 12:43:19'}}\n"
     ]
    }
   ],
   "source": [
    "import os, json, time\n",
    "from urllib.parse import urlparse, unquote\n",
    "from PIL import Image, ExifTags\n",
    "import requests\n",
    "\n",
    "IMG_DIR = \"images\"\n",
    "OUT_JSON = \"data/images_metadata.json\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# 1) Build mapping filename -> {label, pays, source_url}\n",
    "# -----------------------\n",
    "def filename_from_special_file_url(url: str) -> str:\n",
    "    # Special:FilePath/<FILENAME>\n",
    "    return unquote(urlparse(url).path.split(\"/\")[-1])\n",
    "\n",
    "df_all = dataframe.copy()\n",
    "df_all[\"commons_file_name\"] = df_all[\"image\"].apply(filename_from_special_file_url)\n",
    "\n",
    "info_by_file = {}\n",
    "for _, row in df_all.iterrows():\n",
    "    fn = row[\"commons_file_name\"]\n",
    "    if fn not in info_by_file:\n",
    "        info_by_file[fn] = {\n",
    "            \"label\": row.get(\"label\"),\n",
    "            \"pays\": row.get(\"pays\"),\n",
    "            \"source_url\": row.get(\"image\"),\n",
    "        }\n",
    "\n",
    "# -----------------------\n",
    "# 2) Commons API (license)\n",
    "# -----------------------\n",
    "COMMONS_API = \"https://commons.wikimedia.org/w/api.php\"\n",
    "\n",
    "def get_commons_license(file_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retourne un dict simple: {license_short, license_url, usage_terms}\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": f\"File:{file_name}\",\n",
    "        \"prop\": \"imageinfo\",\n",
    "        \"iiprop\": \"extmetadata\",\n",
    "    }\n",
    "    headers = {\"User-Agent\": \"ImageRecoStudentProject/1.0\"}\n",
    "    r = requests.get(COMMONS_API, params=params, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "    page = next(iter(pages.values()), {})\n",
    "    infos = page.get(\"imageinfo\", [])\n",
    "    if not infos:\n",
    "        return {}\n",
    "\n",
    "    ext = infos[0].get(\"extmetadata\", {}) or {}\n",
    "    return {\n",
    "        \"license_short\": ext.get(\"LicenseShortName\", {}).get(\"value\"),\n",
    "        \"license_url\": ext.get(\"LicenseUrl\", {}).get(\"value\"),\n",
    "        \"usage_terms\": ext.get(\"UsageTerms\", {}).get(\"value\"),\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# 3) EXIF (basic)\n",
    "# -----------------------\n",
    "KEEP_EXIF = {\"Model\", \"Make\", \"DateTimeOriginal\", \"DateTime\", \"LensModel\"}\n",
    "\n",
    "def extract_exif_basic(img: Image.Image) -> dict:\n",
    "    try:\n",
    "        exif = img.getexif()\n",
    "        if not exif:\n",
    "            return {}\n",
    "        out = {}\n",
    "        for tag_id, value in exif.items():\n",
    "            tag = ExifTags.TAGS.get(tag_id, str(tag_id))\n",
    "            if tag in KEEP_EXIF and not isinstance(value, (bytes, bytearray)):\n",
    "                out[tag] = value\n",
    "        return out\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "metadata = []\n",
    "seen = set()   # pour éviter les doublons\n",
    "\n",
    "for local_fn in files:\n",
    "    if local_fn in seen:\n",
    "        continue\n",
    "    seen.add(local_fn)\n",
    "\n",
    "    local_path = os.path.join(IMG_DIR, local_fn)\n",
    "\n",
    "    try:\n",
    "        commons_fn = unquote(local_fn)\n",
    "\n",
    "        with Image.open(local_path) as img:\n",
    "            width, height = img.size\n",
    "            fmt = img.format\n",
    "            exif = extract_exif_basic(img)\n",
    "\n",
    "        size_kb = os.path.getsize(local_path) / 1024\n",
    "\n",
    "        base = info_by_file.get(commons_fn, {})\n",
    "        license_info = get_commons_license(commons_fn) if base else {}\n",
    "\n",
    "        metadata.append({\n",
    "            \"file_name\": local_fn,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"format\": fmt,\n",
    "            \"file_size_kb\": round(size_kb, 2),\n",
    "            \"source_url\": base.get(\"source_url\"),\n",
    "            \"label\": base.get(\"label\"),\n",
    "            \"pays\": base.get(\"pays\"),\n",
    "            \"license\": license_info,\n",
    "            \"exif\": exif\n",
    "        })\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "    \n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3cc63",
   "metadata": {},
   "source": [
    "TÂCHE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4949561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
